# Лабораторная работа №2

Цель работы: реализовать простейший алгоритм трекинга объекта на видео на основе ключевых точек.

Задание:
- [x] Реализовать программу согласно описанию. Можно использовать языки C++ или Python и любые библиотеки
- [x] Протестировать алгоритм на трех вариантах тестового видео (также приложен образец)
- [x] Записать свое видео с похожим объектом и протестировать на нем
- [x] Сделать отчёт в виде readme на GitHub,там же должен быть выложен исходный код

---

## 1. Теоретическая база
**Трекинг объектов** - задача определения и отслеживания положения целевого объекта в последовательности видеокадров. 

Для реализации трекинга объекта на видео на основе ключевых точек были применены классические методы компьютерного зрения: 
детектирование углов по методу Ши–Томаси и пирамидальный оптический поток Лукаса–Канаде.

### 1.1. Обнаружение ключевых точек: алгоритм Ши–Томаси (Good Features to Track)
Ключевые точки - это стабильные, репрезентативные участки изображения, которые могут быть надёжно обнаружены на разных кадрах. 
Одним из самых эффективных способов их поиска является метод углов, предложенный Shi и Tomasi в 1994 году как улучшение оригинального детектора Харриса.

Алгоритм основан на анализе структурного тензора (матрицы вторых моментов градиентов):

```
M = Σ [(Ix²,     Ix·Iy  ),
       (Ix·Iy,   Iy²   )]   по окну W,
```

где:
- Ix и Iy — частные производные яркости изображения по координатам x и y,
- суммирование выполняется по локальному окну W.

Угловые точки характеризуются тем, что оба собственных значения λ₁ и λ₂ матрицы M велики.

- Для рёбер: одно значение велико, другое мало.
- Для однородных областей: оба значения малы.

В отличие от детектора Харриса, который использует приближённую оценку (`R = det(M) – k·trace(M)²`) метод Ши–Томаси напрямую требует, 
чтобы меньшее из собственных значений превышало порог: `min(λ₁, λ₂) > threshold`

Это обеспечивает более надёжный отбор точек, устойчивых к шуму и переносимых между кадрами.

В OpenCV этот метод реализован в функции cv2.goodFeaturesToTrack, которая также включает параметры:
- maxCorners — ограничение на общее число возвращаемых точек,
- qualityLevel — порог качества (в долях от качества лучшей точки),
- minDistance — минимальное евклидово расстояние между отобранными точками.

### 1.2. Отслеживание точек: оптический поток Лукаса–Канаде
После обнаружения ключевых точек на первом кадре их положение на последующих кадрах оценивается с помощью 
оптического потока — векторного поля, описывающего движение пикселей между двумя последовательными изображениями.

Алгоритм Лукаса–Канаде (1981) предполагает:
1. Условие постоянства яркости: `I(x, y, t) = I(x + Δx, y + Δy, t + Δt)`, то есть яркость точки не меняется со временем
2. Локальная однородность движения: все точки в малом окне (например, 15×15 пикселей) движутся одинаково.

Линеаризуя условие постоянства яркости, получаем уравнение оптического потока:
`Ix · vx + Iy · vy = –It`, где:
- vx, vy — компоненты скорости (смещения) точки,
- It — производная по времени (разность между кадрами).

Это уравнение недоопределено для одной точки, но становится переопределённым в окне. 
Решение находится методом наименьших квадратов:
```
[ vx ]   =   ( Σ [ Ix²    Ix·Iy ] )⁻¹   ·   ( – Σ [ Ix·It ] )
[ vy ]        (   [ Ix·Iy  Iy²  ] )           (     [ Iy·It ] )
```
(суммирование по окну W)

Для отслеживания при больших смещениях используется пирамидальная реализация (cv2.calcOpticalFlowPyrLK). 
Изображение многократно уменьшается, образуя гауссову пирамиду. 
Оптический поток сначала оценивается на грубом (уменьшенном) уровне, затем уточняется на более детальных. 
Это позволяет отслеживать точки даже при значительных перемещениях.

### 1.3. Построение bounding box
После получения текущих координат отслеживаемых точек строится ось-выровненный ограничивающий прямоугольник:
```
x_min = min(x_i),   x_max = max(x_i)
y_min = min(y_i),   y_max = max(y_i)
```

Хотя такой прямоугольник не учитывает поворот объекта, он прост в вычислении и удовлетворяет требованию
«максимально соответствовать реальным границам» в условиях ЛР2, особенно для фронтальных сцен с плоскими объектами (например, картина, книга, плакат).

Для более точной локализации можно было бы использовать гомографию между шаблоном и текущим кадром 
(на основе найденных соответствий точек), но это выходит за рамки «простейшего алгоритма».

### 1.4. Ограничения подхода
- Требуется текстура: на однородных или слабо текстурированных объектах (например, белый лист) точки не обнаруживаются.
- Чувствительность к освещению и перспективе: изменение условий съёмки может нарушить условие постоянства яркости.
- Отсутствие повторного захвата: при потере трекинга система не пытается заново найти объект.
- Ось-выровненный bbox: не отражает истинную ориентацию объекта при повороте.

Несмотря на эти ограничения, предложенный метод является классическим и дидактически ценным примером feature-based tracking, 
заложившим основу для многих современных систем.

## 2. Описание разработанной системы (алгоритмы, принципы работы, архитектура) 
Разработанная система реализует простейший алгоритм трекинга на основе ключевых точек, где объект задаётся первым кадром видео. 
Система состоит из двух основных компонентов:

### 2.1. Класс FeatureBasedTracker
Отвечает за логику обнаружения и отслеживания:
- `Инициализация`: при получении первого кадра вызывается initialize_tracker(), который использует cv2.goodFeaturesToTrack 
для детекции углов по методу Ши–Томаси
- `Трекинг`: на каждом последующем кадре вызывается process_frame(), который:
  - преобразует кадр в оттенки серого
  - применяет cv2.calcOpticalFlowPyrLK для оценки смещения ключевых точек
  - фильтрует надёжные точки (по флагу status)
  - перезапускает трекинг, если число точек падает ниже порога min_points_for_bbox
- `Визуализация`: метод _draw_features_and_bbox() отрисовывает:
  - зелёные кружки в позициях точек 
  - синий ось-выровненный bounding box
  - текстовую метку «Tracked object»

### 2.2. Класс VideoTracker
Отвечает за взаимодействие с пользователем и обработку видео:
- Автоматически масштабирует окно вывода под заданную максимальную ширину
- Поддерживает интерактивное управление:
  - `q` — выход
  - `+` / `-` — изменение размера окна
  - `f` — переключение полноэкранного режима.
- Обеспечивает корректную инициализацию: первый кадр используется исключительно как шаблон объекта, после чего воспроизводится с начала

### 2.3. Принцип работы
1. Пользователь предоставляет видео, первый кадр которого содержит только целевой объект (без фона или с минимальным).
2. Система извлекает ключевые точки с этого кадра.
3. На всех последующих кадрах точки отслеживаются с помощью пирамидального оптического потока.

## 3. Результаты работы и тестирования системы 

## 4. Выводы по работе 
## 5. Использованные источники 
1. https://docs.opencv.org/3.4/d4/d8c/tutorial_py_shi_tomasi.html
2. https://docs.opencv.org/4.x/d4/dee/tutorial_optical_flow.html
3. 
